{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Generative Adversarial Networks\n",
    "\n",
    "> A different framework for generative learning.\n",
    "\n",
    "<br>\n",
    "\n",
    "(GANs) were introduced by Ian Goodfellow in 2014.  \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "- $\\Omega$ universe of every possible data sample, not matter how unlikely\n",
    "\n",
    "- There's a machine that generates fake data samples, using some noise as input. The machine is called the **generator**.\n",
    "\n",
    "- r are the real data samples. $R$ is the distribution of the real data samples. $p_R$ is the pdf of **realistic** data\n",
    "\n",
    "- f are the fake data samples. $F$ is the distribution of the fake data samples. $p_F$ is the pdf of **fake** data\n",
    "\n",
    "- The goal is to **sequentially** improve the quality of the generator machine samples until they are indistinguishable from the real data samples\n",
    "\n",
    "- The signal for improvement comes from a high pass filter that detects the fake data samples, a machine called the **discriminator**.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "-----\n",
    "\n",
    "\n",
    "# GAN Framework \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "- $z$ are samples from the latent space $Z$, the space of all possible noise vectors. $p_Z$ is the distribution of the latent noise vector\n",
    "\n",
    "<br>\n",
    "\n",
    "- Trained GANs generate realistic data samples (sophisticated fakes) $ F \\subseteq \\Omega $ by learning the unnormalized data distribution\n",
    "\n",
    "<br>\n",
    "\n",
    "- GANs framework consist of two neural network functions and a loss function with two phase gradient descent:  \n",
    "\n",
    "<br>\n",
    "\n",
    "  -   **Generator (G):** Produces fake samples $f=G(z)$ from noise $z \\sim p(z)$.    $ G: Z \\rightarrow \\Omega $\n",
    "\n",
    "<br>\n",
    "\n",
    "  -   **Discriminator (D):** Distinguishes real data $r \\in R$ (where $r \\sim p_R$) from fake samples  $f=G(z) \\in \\Omega$  \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# How GANs Work\n",
    "\n",
    "<br>\n",
    "\n",
    "- Focus is to learn how to generate realistic data samples from noise, a function $G$ called the generator. Avoids direct calculation of the partition function.\n",
    "\n",
    "<br>\n",
    "\n",
    "1. Generator\n",
    "\n",
    "- $G$: Trained to maximize the probability of fooling $D$  \n",
    "\n",
    "<br>\n",
    "\n",
    "- For an innovation $z$, $G(z)$ is a novel observation => random variable $G(Z)$ transforms the input noise $Z$ to quality fakes, close to real data\n",
    "\n",
    "<br>\n",
    "\n",
    "2. Discriminator\n",
    "\n",
    "- $D$: Trained to minimize the probability of being fooled by $G$\n",
    "\n",
    "<br>\n",
    "\n",
    "- For a novel observation $u$, $D(u)$ is  a probability: $D(u) = p(\\text{Real Observation} | u) = 1 - p(\\text{Fake Observation} | u)$ defines a Bernoulli random variable\n",
    "\n",
    "<br>\n",
    "\n",
    "- Loss function:  \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\min_G \\max_D V(D, G) = \\mathbb{E}_{R}[\\log D(R)] + \\mathbb{E}_{Z}[\\log(1 - D(G(Z)))]\n",
    "$$  \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# Key Insights\n",
    "\n",
    "<br>\n",
    "\n",
    "- At **equilibrium**, $G$ generates samples indistinguishable from real data  \n",
    "\n",
    "<br>\n",
    "\n",
    "- $D$ provides feedback to $G$ for improvement  \n",
    "\n",
    "<br>\n",
    "\n",
    "- Challenges in GAN training:  \n",
    "\n",
    "<br>\n",
    "\n",
    "  - **Mode Collapse:** Limited variety in generated data  \n",
    "\n",
    "<br>\n",
    "\n",
    "  - **Training Instability:** Difficult to balance $G$ and $D$  \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# Innovations in GANs\n",
    "\n",
    "<br>\n",
    "\n",
    "- Adversarial training using specialized loss functions\n",
    "\n",
    "<br>\n",
    "\n",
    "- Presented as a zero-sum **minimax optimization problem** (not needed)\n",
    "\n",
    "<br>\n",
    "\n",
    "- Wrapped in Fixed Point Theory (or Nash Equilibrium if you want to be lazy)\n",
    "\n",
    "<br>\n",
    "\n",
    "- Roots in Jurgen Schmidhuber's 1990 work [Artificial Curiosity](https://people.idsia.ch/~juergen/artificial-curiosity-since-1990.html) and 2012 work from Battista Biggio et al. on [Poisoning Attacks](https://arxiv.org/abs/1206.6389)\n",
    "<br>\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# Comments: GANs\n",
    "\n",
    "<br>\n",
    "\n",
    "- Original paper goes on side tangents about **zero sum games**, **minimax optimization** and nash equilibria.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "- Notation is awkward and inconsistent\n",
    "\n",
    "<br>\n",
    "\n",
    "- No obvious evaluation/fit scoring for GANs \n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "- Misses that the generator is non-invertible mapping from the latent space to the data space.\n",
    "\n",
    "<br>\n",
    "\n",
    "- Doesn't carefully discuss the partition function is avoided by the GAN framework.\n",
    "\n",
    "<br>\n",
    "\n",
    "- Invertible GANs (or normalizing flows) generalize GANs to firmer statistical grounds.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# Extensions of Vanilla GANs\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Deep Convolutional GANs (DC-GANs):** Use CNNs for image generation.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Wasserstein GANs (W-GANs):** Use Wasserstein distance for more stable training.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **CycleGANs:** Convert images between domains (e.g., photos → paintings).\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Conditional GANs:** Generate samples conditioned on specific data.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **StyleGANs:** Generate images with specific styles and features.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **InfoGANs:** Learn interpretable representations in latent space.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# GANs less Hype in 2024\n",
    "\n",
    "<br>\n",
    "\n",
    "* \tInitial Hype Over: GANs are no longer the only game in town for generative learning\n",
    "\n",
    "<br>\n",
    "\n",
    "* \tDiffusion Models: Superior sample diversity, stability, and quality (e.g., DALL·E 2, Imagen).\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "* Normalizing Flows: Stable, interpretable, and tractable for density estimation (e.g., RealNVP, Glow).\n",
    "\n",
    "<br>\n",
    "\n",
    "* VAEs: Stable training and better latent space interpretability, but lower sample quality.\n",
    "\n",
    "<br>\n",
    "\n",
    "* Autoregressive Models: Best for complex dependencies (e.g., PixelCNN, GPT-3).\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# GANs still SoTA in few Areas\n",
    "\n",
    "<br>\n",
    "\n",
    "* \tUltra High-Resolution Image Generation: StyleGAN2/3 produce realistic, detailed images, especially for faces\n",
    "\n",
    "<br>\n",
    "\n",
    "* \tImage-to-Image Translation: GANs like Pix2Pix and CycleGAN excel in tasks like style transfer and photo enhancement \n",
    "\n",
    "<br>\n",
    "\n",
    "* \tCreative Content Generation: Used widely in art, design, and animation for producing novel content\n",
    "\n",
    "<br>\n",
    "\n",
    "*\tConditional Generation: cGANs generate images from text or sketches with high fidelity\n",
    "\n",
    "<br>\n",
    "\n",
    "*\tReal-Time Performance: GANs are preferred in applications requiring fast image generation, like gaming and VR\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "<br>\n",
    "\n",
    "- GANs demonstrate the power of **adversarial training** for synthetic data generation.  \n",
    "\n",
    "<br>\n",
    "\n",
    "- GANs are a **zero-sum game** between a generator and a discriminator.\n",
    "\n",
    "<br>\n",
    "\n",
    "- Although innovative, GANs have limitations like **mode collapse** and **training instability**.\n",
    "\n",
    "<br>\n",
    "\n",
    "- Probably not going to solve AGI\n",
    "\n",
    "<br>\n",
    "\n",
    "**References:**  \n",
    "\n",
    "<br>\n",
    "\n",
    "For more, see [Goodfellow et al. (2014)](https://arxiv.org/abs/1406.2661).  \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# Conditional GANs\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Conditional GANs:** Generate samples conditioned on specific data.\n",
    "\n",
    "<br>\n",
    "\n",
    "- In practice, the generator and discriminator are augmented with the conditioning data as inputs.\n",
    "\n",
    "<br>\n",
    "\n",
    "- if GAN generator has input $Z$ and output $G(Z)$, the conditional GAN generator has input $(Z, y)$ and output $G(Z|y)$. \n",
    "\n",
    "<br>\n",
    "\n",
    "- If GAN discriminator has input $X$ and output $D(X)$, the conditional GAN discriminator has input $(X, y)$ and output $D(X|y)$.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Conditional GANs Applications:**\n",
    "\n",
    "  - Image-to-Image Translation\n",
    "  - Text-to-Image Generation\n",
    "  - Image Super-Resolution\n",
    "  - Image Inpainting\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# Wasserstein GANs\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Wasserstein GANs (W-GANs):** Use Wasserstein distance for more stable training.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Wasserstein Distance:** Measures the distance between two probability distributions.\n",
    "\n",
    "<br>\n",
    "\n",
    "- Wasserstein GAN Loss Function:\n",
    "\n",
    "$$\n",
    "L_D = \\mathbb{E}_{R}[D(R)] - \\mathbb{E}_{Z}[D(G(Z))]\n",
    "$$\n",
    "\n",
    "$$\n",
    "L_G = -\\mathbb{E}_{Z}[D(G(Z))]\n",
    "$$\n",
    "\n",
    "\n",
    "- Regularized Wasserstein GAN\n",
    "\n",
    "$$\n",
    "L_D = \\mathbb{E}_{R}[D(R)] - \\mathbb{E}_{Z}[D(G(Z))] + \\lambda \\mathbb{E}_{Z}[(||\\nabla_{G(Z)} D(G(Z))||_2 - 1)^2]\n",
    "$$\n",
    "\n",
    "$$\n",
    "L_G = -\\mathbb{E}_{Z}[D(G(Z))]\n",
    "$$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# CycleGANs\n",
    "\n",
    "<br>\n",
    "\n",
    "- **CycleGANs:** Convert images between domains (e.g., photos → paintings).\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Cycle-Consistency Loss:** Ensures that the converted image can be converted back to the original image.\n",
    "\n",
    "<br>\n",
    "\n",
    "- CycleGAN Loss Function:\n",
    "\n",
    "$$\n",
    "L_{GAN}(G, D_Y, X, Y) = \\mathbb{E}_{y \\sim p_{data}(y)}[\\log D_Y(y)] + \\mathbb{E}_{x \\sim p_{data}(x)}[\\log(1 - D_Y(G(x)))]\n",
    "$$\n",
    "\n",
    "$$\n",
    "L_{cyc}(G, F) = \\mathbb{E}_{x \\sim p_{data}(x)}[||F(G(x)) - x||_1]\n",
    "$$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
